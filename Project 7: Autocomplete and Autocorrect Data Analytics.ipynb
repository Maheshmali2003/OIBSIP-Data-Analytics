{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e17bd7",
   "metadata": {},
   "source": [
    "# project 7 : Autocomplete and Autocorrect Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c8839",
   "metadata": {},
   "source": [
    "# Description:Explore the efficiency and accuracy of autocomplete and autocorrect algorithms in naturallanguage processing (NLP) through this data analytics project. The objective is to enhance userexperience and text prediction by analyzing large datasets and implementing or optimizingautocomplete and autocorrect functionalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214f4903",
   "metadata": {},
   "source": [
    "# Key Concepts and Challenges:\n",
    "    \n",
    "Dataset Collection: Gather 1. diverse text data.\n",
    "    \n",
    "2.NLP Preprocessing: Clean and prepare data for analysis.\n",
    "    \n",
    "3.Autocomplete: Implement algorithms for word/phrase predictions.\n",
    "    \n",
    "4.Autocorrect: Optimize algorithms for spelling error correction.\n",
    "    \n",
    "5.Metrics: Define and measure performance metrics.\n",
    "    \n",
    "6.User Experience: Assess impact through feedback and surveys.\n",
    "    \n",
    "7.Algorithm Comparison: Evaluate different models for efficiency and accuracy.\n",
    "    \n",
    "8.Visualization: Use tools for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1629bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f4cef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab6c8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc064ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: This is an example sentence for NLP preprocessing.\n",
      "Preprocessed text: example sentence nlp preprocessing\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    \n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Example usage:\n",
    "text = \"This is an example sentence for NLP preprocessing.\"\n",
    "clean_text = preprocess_text(text)\n",
    "print(\"Original text:\", text)\n",
    "print(\"Preprocessed text:\", clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ddb1c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocomplete predictions for prefix 'economic growth':\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import reuters\n",
    "from nltk.util import ngrams\n",
    "import random\n",
    "\n",
    "class Autocomplete:\n",
    "    def __init__(self, n):\n",
    "        self.n = n  # Specify the order of the n-gram model\n",
    "        self.ngrams = defaultdict(list)\n",
    "\n",
    "    def train(self, text):\n",
    "        tokens = word_tokenize(text)\n",
    "        for ngram in ngrams(tokens, self.n):\n",
    "            prefix = ' '.join(ngram[:-1])\n",
    "            self.ngrams[prefix].append(ngram[-1])\n",
    "\n",
    "    def predict(self, prefix, num_predictions=3):\n",
    "        if prefix not in self.ngrams:\n",
    "            return None\n",
    "        return random.choices(self.ngrams[prefix], k=num_predictions)\n",
    "\n",
    "# Example usage:\n",
    "text = reuters.raw()  # Using the Reuters corpus for training\n",
    "autocomplete = Autocomplete(n=2)  # Using a bigram model\n",
    "autocomplete.train(text)\n",
    "\n",
    "prefix = 'economic growth'  # Example prefix for prediction\n",
    "predictions = autocomplete.predict(prefix)\n",
    "print(\"Autocomplete predictions for prefix '{}':\".format(prefix))\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc582d28",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m autocorrect \u001b[38;5;241m=\u001b[39m Autocorrect(vocabulary)\n\u001b[0;32m     25\u001b[0m word \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moragne\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Example misspelled word\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m correction \u001b[38;5;241m=\u001b[39m autocorrect\u001b[38;5;241m.\u001b[39msuggest_correction(word)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutocorrect suggestion for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(word, correction))\n",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m, in \u001b[0;36mAutocorrect.suggest_correction\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msuggest_correction\u001b[39m(\u001b[38;5;28mself\u001b[39m, word):\n\u001b[0;32m      9\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_candidates(word)\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(candidates, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocabulary\u001b[38;5;241m.\u001b[39mget)\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "class Autocorrect:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.vocabulary = Counter(vocabulary)\n",
    "\n",
    "    def suggest_correction(self, word):\n",
    "        candidates = self.generate_candidates(word)\n",
    "        return max(candidates, key=self.vocabulary.get)\n",
    "\n",
    "    def generate_candidates(self, word):\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "        deletes = [left + right[1:] for left, right in splits if right]\n",
    "        transposes = [left + right[1] + right[0] + right[2:] for left, right in splits if len(right) > 1]\n",
    "        replaces = [left + letter + right[1:] for left, right in splits if right for letter in letters]\n",
    "        inserts = [left + letter + right for left, right in splits for letter in letters]\n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "# Example usage:\n",
    "vocabulary = [\"apple\", \"banana\", \"orange\", \"pear\", \"peach\"]\n",
    "autocorrect = Autocorrect(vocabulary)\n",
    "\n",
    "word = \"oragne\"  # Example misspelled word\n",
    "correction = autocorrect.suggest_correction(word)\n",
    "print(\"Autocorrect suggestion for '{}' is '{}'.\".format(word, correction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self, true_positives, false_positives, false_negatives):\n",
    "        self.true_positives = true_positives\n",
    "        self.false_positives = false_positives\n",
    "        self.false_negatives = false_negatives\n",
    "    \n",
    "    def accuracy(self):\n",
    "        total_predictions = self.true_positives + self.false_positives + self.false_negatives\n",
    "        return self.true_positives / total_predictions\n",
    "    \n",
    "    def precision(self):\n",
    "        return self.true_positives / (self.true_positives + self.false_positives)\n",
    "    \n",
    "    def recall(self):\n",
    "        return self.true_positives / (self.true_positives + self.false_negatives)\n",
    "    \n",
    "    def f1_score(self):\n",
    "        precision = self.precision()\n",
    "        recall = self.recall()\n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Example usage:\n",
    "true_positives = 80\n",
    "false_positives = 10\n",
    "false_negatives = 5\n",
    "\n",
    "metrics = Metrics(true_positives, false_positives, false_negatives)\n",
    "print(\"Accuracy:\", metrics.accuracy())\n",
    "print(\"Precision:\", metrics.precision())\n",
    "print(\"Recall:\", metrics.recall())\n",
    "print(\"F1 Score:\", metrics.f1_score())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e8fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from survey import Survey\n",
    "\n",
    "# Define the survey questions\n",
    "survey = Survey({\n",
    "    \"1. How satisfied are you with the autocomplete feature?\": [\"Very satisfied\", \"Satisfied\", \"Neutral\", \"Dissatisfied\", \"Very dissatisfied\"],\n",
    "    \"2. How accurate do you find the autocomplete suggestions?\": [\"Very accurate\", \"Accurate\", \"Neutral\", \"Inaccurate\", \"Very inaccurate\"],\n",
    "    \"3. How easy is it to use the autocorrect feature?\": [\"Very easy\", \"Easy\", \"Neutral\", \"Difficult\", \"Very difficult\"],\n",
    "    \"4. Any additional comments or suggestions?\": \"\"\n",
    "})\n",
    "\n",
    "# Collect responses\n",
    "responses = survey.ask()\n",
    "\n",
    "# Print responses\n",
    "print(\"Survey Responses:\")\n",
    "for question, answer in responses.items():\n",
    "    print(question + \":\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd85094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "class NGramAutocomplete:\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self.ngram_counts = defaultdict(int)\n",
    "\n",
    "    def train(self, corpus):\n",
    "        for sentence in corpus:\n",
    "            tokens = sentence.split()\n",
    "            for ngram in ngrams(tokens, self.n):\n",
    "                self.ngram_counts[ngram] += 1\n",
    "\n",
    "    def predict(self, prefix):\n",
    "        predictions = []\n",
    "        for ngram, count in self.ngram_counts.items():\n",
    "            if ngram[:len(prefix)] == tuple(prefix.split()):\n",
    "                predictions.append((ngram[-1], count))\n",
    "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [prediction[0] for prediction in predictions]\n",
    "\n",
    "class TrieAutocomplete:\n",
    "    def __init__(self):\n",
    "        self.trie = defaultdict(dict)\n",
    "\n",
    "    def insert(self, word):\n",
    "        node = self.trie\n",
    "        for char in word:\n",
    "            if char not in node:\n",
    "                node[char] = {}\n",
    "            node = node[char]\n",
    "        node['$'] = True\n",
    "\n",
    "    def search(self, prefix):\n",
    "        node = self.trie\n",
    "        for char in prefix:\n",
    "            if char not in node:\n",
    "                return []\n",
    "            node = node[char]\n",
    "        return self._dfs(node, prefix)\n",
    "\n",
    "    def _dfs(self, node, prefix):\n",
    "        if '$' in node:\n",
    "            return [prefix]\n",
    "        results = []\n",
    "        for char, child_node in node.items():\n",
    "            if char != '$':\n",
    "                results.extend(self._dfs(child_node, prefix + char))\n",
    "        return results\n",
    "\n",
    "# Example usage:\n",
    "corpus = [\"the quick brown fox jumps over the lazy dog\", \"the quick brown cat jumps over the lazy dog\"]\n",
    "prefix = \"the quick\"\n",
    "n = 2\n",
    "\n",
    "# Instantiate and train NGramAutocomplete\n",
    "ngram_autocomplete = NGramAutocomplete(n)\n",
    "ngram_autocomplete.train(corpus)\n",
    "\n",
    "# Instantiate TrieAutocomplete\n",
    "trie_autocomplete = TrieAutocomplete()\n",
    "for sentence in corpus:\n",
    "    for word in sentence.split():\n",
    "        trie_autocomplete.insert(word)\n",
    "\n",
    "# Test NGramAutocomplete\n",
    "start_time = time.time()\n",
    "predictions_ngram = ngram_autocomplete.predict(prefix)\n",
    "print(\"NGramAutocomplete predictions:\", predictions_ngram)\n",
    "print(\"Time taken for NGramAutocomplete:\", time.time() - start_time)\n",
    "\n",
    "# Test TrieAutocomplete\n",
    "start_time = time.time()\n",
    "predictions_trie = trie_autocomplete.search(prefix)\n",
    "print(\"TrieAutocomplete predictions:\", predictions_trie)\n",
    "print(\"Time taken for TrieAutocomplete:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the algorithms and their performance metrics\n",
    "algorithms = ['Algorithm 1', 'Algorithm 2', 'Algorithm 3']\n",
    "accuracy = [0.85, 0.90, 0.88]\n",
    "precision = [0.82, 0.87, 0.85]\n",
    "recall = [0.88, 0.92, 0.90]\n",
    "f1_score = [0.85, 0.89, 0.87]\n",
    "\n",
    "# Create subplots for each metric\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Plot accuracy\n",
    "axs[0, 0].bar(algorithms, accuracy, color='blue')\n",
    "axs[0, 0].set_title('Accuracy')\n",
    "axs[0, 0].set_ylabel('Score')\n",
    "\n",
    "# Plot precision\n",
    "axs[0, 1].bar(algorithms, precision, color='green')\n",
    "axs[0, 1].set_title('Precision')\n",
    "axs[0, 1].set_ylabel('Score')\n",
    "\n",
    "# Plot recall\n",
    "axs[1, 0].bar(algorithms, recall, color='orange')\n",
    "axs[1, 0].set_title('Recall')\n",
    "axs[1, 0].set_ylabel('Score')\n",
    "\n",
    "# Plot F1 score\n",
    "axs[1, 1].bar(algorithms, f1_score, color='red')\n",
    "axs[1, 1].set_title('F1 Score')\n",
    "ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57f704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f6fae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
